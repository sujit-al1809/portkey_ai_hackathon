# ğŸ“ Repository Structure

```
portkey_ai_hackathon/
â”‚
â”œâ”€â”€ ğŸ“„ main.py                      # Main demo entry point
â”œâ”€â”€ ğŸ”„ continuous_mode.py           # Continuous monitoring daemon
â”œâ”€â”€ âš™ï¸  config.py                    # Configuration settings
â”œâ”€â”€ ğŸ“Š models.py                    # Data models (Pydantic/dataclass)
â”œâ”€â”€ ğŸ”„ replay_engine.py             # Multi-model replay system
â”œâ”€â”€ âš–ï¸  quality_evaluator.py         # LLM-as-judge evaluation
â”œâ”€â”€ ğŸ“ˆ optimizer.py                 # Cost-quality trade-off analysis
â”œâ”€â”€ ğŸ’¾ state_manager.py             # State persistence & caching
â”œâ”€â”€ ğŸ” continuous_monitor.py        # Continuous operation orchestrator
â”‚
â”œâ”€â”€ ğŸ“š docs/                        # Documentation
â”‚   â”œâ”€â”€ ğŸ“– SETUP.md                 # Detailed setup instructions
â”‚   â”œâ”€â”€ ğŸ¤ PITCH.md                 # Project pitch deck
â”‚   â””â”€â”€ ğŸ“‹ PROJECT_SUMMARY.md       # Complete project overview
â”‚
â”œâ”€â”€ ğŸ§ª tests/                       # Test files
â”‚   â”œâ”€â”€ âœ… test_config.py           # Configuration validation
â”‚   â”œâ”€â”€ ğŸš€ simple_test.py           # Simple API test
â”‚   â””â”€â”€ ğŸ“ quickstart.py            # Quick start guide
â”‚
â”œâ”€â”€ ğŸ’¾ data/                        # Data storage (gitignored)
â”‚   â”œâ”€â”€ replay_state.json           # Processing state
â”‚   â”œâ”€â”€ optimization_results.json   # Optimization results
â”‚   â””â”€â”€ evaluation_cache.json       # Evaluation cache
â”‚
â”œâ”€â”€ ğŸ”§ Configuration Files
â”‚   â”œâ”€â”€ .env.example                # Environment variables template
â”‚   â”œâ”€â”€ .gitignore                  # Git ignore patterns
â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“– Documentation
â”‚   â”œâ”€â”€ README.md                   # Main documentation (you are here)
â”‚   â”œâ”€â”€ CONTRIBUTING.md             # Contribution guidelines
â”‚   â””â”€â”€ LICENSE                     # MIT License
â”‚
â””â”€â”€ ğŸ—‚ï¸  Other
    â”œâ”€â”€ venv/                       # Virtual environment (gitignored)
    â””â”€â”€ __pycache__/                # Python cache (gitignored)
```

## ğŸ“Š Component Overview

### Core Components

| Component | Purpose | Key Features |
|-----------|---------|--------------|
| ğŸ”„ **Replay Engine** | Multi-model testing | Retries, timeout handling, cost tracking |
| âš–ï¸ **Quality Evaluator** | LLM-as-judge | Dimensional scoring, confidence levels |
| ğŸ“ˆ **Optimizer** | Trade-off analysis | Statistical analysis, recommendations |
| ğŸ’¾ **State Manager** | Persistence | Incremental processing, caching |
| ğŸ” **Continuous Monitor** | Orchestration | Continuous operation, batch processing |

### Data Flow

```
ğŸ“¥ Prompts â†’ ğŸ”„ Replay Engine â†’ âš–ï¸ Quality Evaluator â†’ ğŸ“ˆ Optimizer â†’ ğŸ’¾ State Manager â†’ ğŸ“Š Recommendations
```

### File Sizes (Approximate)

- **Source Code**: ~2,000 lines
- **Documentation**: ~1,500 lines
- **Tests**: ~300 lines
- **Total Project**: ~4,000 lines

## ğŸ¯ Quick Navigation

- ğŸš€ [Getting Started](../README.md#-quick-start)
- âš™ï¸ [Configuration](../README.md#-configuration)
- ğŸ“Š [How It Works](../README.md#-how-it-works)
- ğŸ† [Why This Wins](../README.md#-why-this-wins)
- ğŸ¤ [Contributing](../CONTRIBUTING.md)

## ğŸ“ File Descriptions

### Main Application Files

- **main.py**: Demo entry point with sample prompts
- **continuous_mode.py**: Long-running daemon for continuous monitoring
- **config.py**: Central configuration for models, thresholds, criteria

### Core Logic

- **replay_engine.py**: Handles multi-model API calls with retry logic
- **quality_evaluator.py**: Implements LLM-as-judge evaluation
- **optimizer.py**: Analyzes cost-quality trade-offs
- **state_manager.py**: Manages persistence and caching
- **continuous_monitor.py**: Orchestrates the entire pipeline

### Data Models

- **models.py**: Pydantic/dataclass definitions for:
  - PromptData
  - CompletionResult
  - QualityScore
  - OptimizationRecommendation

### Documentation

- **README.md**: Main project documentation
- **docs/SETUP.md**: Detailed setup instructions
- **docs/PITCH.md**: Project pitch and value proposition
- **docs/PROJECT_SUMMARY.md**: Comprehensive overview
- **CONTRIBUTING.md**: How to contribute

### Tests

- **tests/test_config.py**: Validates Portkey configuration
- **tests/simple_test.py**: Quick API connectivity test
- **tests/quickstart.py**: Interactive getting started guide

## ğŸ”„ Data Persistence

All data files are stored in the `data/` directory:

```
data/
â”œâ”€â”€ replay_state.json           # Current processing state
â”œâ”€â”€ optimization_results.json   # Historical recommendations
â””â”€â”€ evaluation_cache.json       # Cached quality evaluations
```

These files enable:
- â™¾ï¸ Continuous operation
- ğŸš« No duplicate work
- ğŸ“Š Historical analysis
- ğŸ”„ Resume from crashes

## ğŸ› ï¸ Development Workflow

1. **Setup**: Create venv, install requirements
2. **Configure**: Set Portkey API key, configure models
3. **Test**: Run test_config.py to validate setup
4. **Develop**: Make changes to core components
5. **Test**: Run simple_test.py and main.py
6. **Deploy**: Run continuous_mode.py for production

---

**ğŸ“š For more details, see the [README](../README.md)**
